{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T01:14:21.048660Z","iopub.execute_input":"2024-08-05T01:14:21.049426Z","iopub.status.idle":"2024-08-05T01:14:21.056371Z","shell.execute_reply.started":"2024-08-05T01:14:21.049381Z","shell.execute_reply":"2024-08-05T01:14:21.055253Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# *Text Reduction*\n___\n#### This project aims to reduce texts from the internet using NLP techniques.","metadata":{}},{"cell_type":"markdown","source":"# Packages :","metadata":{}},{"cell_type":"code","source":"!pip install beautifulsoup4","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:21.058083Z","iopub.execute_input":"2024-08-05T01:14:21.058461Z","iopub.status.idle":"2024-08-05T01:14:33.319723Z","shell.execute_reply.started":"2024-08-05T01:14:21.058432Z","shell.execute_reply":"2024-08-05T01:14:33.318389Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import  word_tokenize,sent_tokenize\nimport re\nimport requests\nfrom bs4 import BeautifulSoup\nimport string\n\nstopwords = nltk.download('stopwords')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.321553Z","iopub.execute_input":"2024-08-05T01:14:33.321957Z","iopub.status.idle":"2024-08-05T01:14:33.330544Z","shell.execute_reply.started":"2024-08-05T01:14:33.321920Z","shell.execute_reply":"2024-08-05T01:14:33.329027Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"stopwords = nltk.corpus.stopwords.words('english')\nstopwords.append(\"href=\")\nstopwords.append(\"class=\")\nstopwords.append(\"id=\")\nstopwords.append(\"title=\")","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.332497Z","iopub.execute_input":"2024-08-05T01:14:33.332972Z","iopub.status.idle":"2024-08-05T01:14:33.357453Z","shell.execute_reply.started":"2024-08-05T01:14:33.332932Z","shell.execute_reply":"2024-08-05T01:14:33.356179Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ponc = string.punctuation + \"  '' ,\\\"\\\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.358815Z","iopub.execute_input":"2024-08-05T01:14:33.359160Z","iopub.status.idle":"2024-08-05T01:14:33.367839Z","shell.execute_reply.started":"2024-08-05T01:14:33.359130Z","shell.execute_reply":"2024-08-05T01:14:33.366715Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ponc","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.369112Z","iopub.execute_input":"2024-08-05T01:14:33.369480Z","iopub.status.idle":"2024-08-05T01:14:33.382895Z","shell.execute_reply.started":"2024-08-05T01:14:33.369449Z","shell.execute_reply":"2024-08-05T01:14:33.381704Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~  \\'\\' ,\"\"'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Get articals:","metadata":{}},{"cell_type":"code","source":"url = \"https://en.wikipedia.org/wiki/Artificial_intelligence\"","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.386128Z","iopub.execute_input":"2024-08-05T01:14:33.386566Z","iopub.status.idle":"2024-08-05T01:14:33.395737Z","shell.execute_reply.started":"2024-08-05T01:14:33.386532Z","shell.execute_reply":"2024-08-05T01:14:33.394467Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def weghts_extracting(url):\n    \n    responce = requests.get(url)\n    \n    html = responce.text\n    html_obj = BeautifulSoup(html,'html.parser')\n    \n    # find all paragraphs\n    all_paragraph = html_obj.find_all(\"p\")\n    \n    # remove html tags\n    pattren = \"\\<\\/?.{1,4}\\>\"\n    pattren2 = \"\\<a.{0,100}\\>\"\n    \n    all_paragraph = [re.sub(pattren,\"\",str(i)) for i in all_paragraph]\n    all_paragraph = [re.sub(pattren2,\"\",str(i)) for i in all_paragraph]\n    clean_txt = all_paragraph\n    \n    # tokenize words\n    all_paragraph = [word_tokenize(txt.lower()) for txt in all_paragraph]\n    \n    # remove punctuation\n    all_paragraph = [[word for word in txt if word not in ponc] for txt in all_paragraph]\n    \n    # remove stopwords\n    all_paragraph = [[word for word in txt if word not in stopwords] for txt in all_paragraph]\n    \n    # words freq\n    word_fr = {}\n\n    for txt in all_paragraph:\n        for word in txt:\n            if word in word_fr.keys():\n                word_fr[word] += 1\n            else:\n                word_fr[word] = 1\n                \n    # get max freq\n    max_val = max(word_fr.values())\n    \n    # normalizeation\n    word_fr_nrml = {}\n    for key,val in word_fr.items():\n        word_fr_nrml[key] = val/max_val\n        \n    return clean_txt , word_fr_nrml\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.397238Z","iopub.execute_input":"2024-08-05T01:14:33.397582Z","iopub.status.idle":"2024-08-05T01:14:33.408951Z","shell.execute_reply.started":"2024-08-05T01:14:33.397536Z","shell.execute_reply":"2024-08-05T01:14:33.407811Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"clean_text, word_fr = weghts_extracting(url)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:14:33.410894Z","iopub.execute_input":"2024-08-05T01:14:33.411804Z","iopub.status.idle":"2024-08-05T01:14:34.593104Z","shell.execute_reply.started":"2024-08-05T01:14:33.411760Z","shell.execute_reply":"2024-08-05T01:14:34.591973Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def text_reduction(clean_text,word_frq,threshold=2):\n    \n    tokenized = [sent_tokenize(txt) for txt in clean_text]\n    \n    \n    sents_res = {}\n    for txt in tokenized:\n        for sent in txt:\n            sents_res[sent] = 0\n            for word in word_tokenize(sent):\n                if word in word_frq.keys():\n                    sents_res[sent] += word_frq[word]\n                    \n    sents_res_keys = []\n    sents_res_values = np.array([], dtype=\"float64\")\n\n    for k,v in sents_res.items():\n        sents_res_keys.append(k)\n        sents_res_values = np.append(sents_res_values, v)\n        \n    threshold_prc = threshold*max(sents_res_values)/100\n    \n    for cnt in range(len(sents_res)):\n        if sents_res_values[cnt] >=threshold_prc:\n            print(sents_res_keys[cnt])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:21:43.321251Z","iopub.execute_input":"2024-08-05T01:21:43.322224Z","iopub.status.idle":"2024-08-05T01:21:43.333131Z","shell.execute_reply.started":"2024-08-05T01:21:43.322159Z","shell.execute_reply":"2024-08-05T01:21:43.331707Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"text_reduction(clean_text, word_fr,80)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T01:21:43.763405Z","iopub.execute_input":"2024-08-05T01:21:43.763928Z","iopub.status.idle":"2024-08-05T01:21:43.967899Z","shell.execute_reply.started":"2024-08-05T01:21:43.763885Z","shell.execute_reply":"2024-08-05T01:21:43.965956Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Alan Turing was the first person to conduct substantial research in the field that he called machine intelligence.<sup class=\"reference\" id=\"cite_ref-turing_5-0\">[5] Artificial intelligence was founded as an academic discipline in 1956,<sup class=\"reference\" id=\"cite_ref-Dartmouth_workshop_6-0\">[6] by those now considered the founding fathers of AI: John McCarthy, Marvin Minksy, <a href=\"/wiki/Nathaniel_Rochester_(computer_scientist)\" title=\"Nathaniel Rochester (computer scientist)\">Nathaniel Rochester, and Claude Shannon.<sup class=\"reference\" id=\"cite_ref-7\">[8] The field went through multiple cycles of optimism,<sup class=\"reference\" id=\"cite_ref-AI_in_the_60s_9-0\">[10] followed by periods of disappointment and loss of funding, known as AI winter.<sup class=\"reference\" id=\"cite_ref-First_AI_winter_11-0\">[12] Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques,<sup class=\"reference\" id=\"cite_ref-Deep_learning_revolution_13-0\">[13] and after 2017 with the <a class=\"mw-redirect\" href=\"/wiki/Transformer_(machine_learning_model)\" title=\"Transformer (machine learning model)\">transformer architecture.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEToews2023_14-0\">AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant <a class=\"mw-redirect\" href=\"/wiki/Advances_in_artificial_intelligence\" title=\"Advances in artificial intelligence\">advances in artificial intelligence.<sup class=\"reference\" id=\"cite_ref-FOOTNOTEFrank2023_15-0\">[15]\nThe study of logic led directly to Alan Turing's theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig20219_305-0\">[289]<sup class=\"reference\" id=\"cite_ref-turing_5-1\">[5] This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\".<sup class=\"reference\" id=\"cite_ref-307\">[q]\nThey developed several areas of research that would become part of AI,<sup class=\"reference\" id=\"cite_ref-308\">[291]\nsuch as McCullouch and Pitts design for \"artificial neurons\" in 1943,<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig202117_309-0\">[292] and Turing's influential 1950 paper 'Computing Machinery and Intelligence', which introduced the Turing test and showed that \"machine intelligence\" was plausible.<sup class=\"reference\" id=\"cite_ref-Turing_test_310-0\">[5]\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.<sup class=\"reference\" id=\"cite_ref-FOOTNOTENewquist199486–86_318-0\">[297] Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".<sup class=\"reference\" id=\"cite_ref-319\">Marvin Minsky agreed, writing, \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".<sup class=\"reference\" id=\"cite_ref-320\">[299] They had, however, underestimated the difficulty of the problem.<sup class=\"reference\" id=\"cite_ref-322\">[v] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill<sup class=\"reference\" id=\"cite_ref-FOOTNOTELighthill1973_323-0\">[301] and ongoing pressure from the U.S. Congress to fund more productive projects.<sup class=\"reference\" id=\"cite_ref-FOOTNOTENRC1999212–213_324-0\">[302] Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig202122_325-0\">[303] The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.<sup class=\"reference\" id=\"cite_ref-First_AI_winter_11-1\">[11]\nIn the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig202124_327-0\">[305] and began to look into \"sub-symbolic\" approaches.<sup class=\"reference\" id=\"cite_ref-FOOTNOTENilsson19987_328-0\">[306] Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive.<sup class=\"reference\" id=\"cite_ref-333\">Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.<sup class=\"reference\" id=\"cite_ref-Uncertain_reasoning_97-1\">[91]<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig202125_334-0\">[311] But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others.<sup class=\"reference\" id=\"cite_ref-335\">Yann LeCun successfully showed that <a class=\"mw-redirect\" href=\"/wiki/Convolutional_neural_networks\" title=\"Convolutional neural networks\">convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.<sup class=\"reference\" id=\"cite_ref-FOOTNOTERussellNorvig202126_336-0\">[313]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}